{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Cross-modal retrieval across audio and images","text":"This project aims to retrieve the pertinent sample across images and audio. DatasetWikipedia Dataset [1]The collected documents are selected sections from the Wikipedia’s featured articles collection. This is a continuously growing dataset, that at the time of collection (October 2009) had 2,669 articles spread over 29 categories. Some of the categories are very scarce, therefore we considered only the 10 most populated ones. The articles generally have multiple sections and pictures. We have split them into sections based on section headings, and assign each image to the section in which it was placed by the author(s). Then this dataset was prunned to keep only sections that contained a single image and at least 70 words.The final corpus contains 2,866 multimedia documents. The median text length is 200 words.You can download Wikipedia Dataset from here. PASCAL sentences Dataset [2]This dataset contains 1,000 images from 20 categories, and each image has 5 corresponding sentences as exact descriptions.The original dataset is posted on this website.You can download this dataset through rupy’s python program.However, rupy’s python program is based on Python 2. The modified programis based on Python 3, and you can use the program as described in rupy’s program. IAPR TC-12 DatasetThe image collection of the IAPR TC-12 Benchmark consists of 20,000 still natural images taken from locations around the world and comprising an assorted cross-section of still natural images. This includes pictures of different sports and actions, photographs of people, animals, cities, landscapes and many other aspects of contemporary life.Each image is associated with a text caption in up to three different languages (English, German and Spanish) . These annotations are stored in a database which is managed by a benchmark administration system that allows the specification of parameters according to which different subsets of the image collection can be generated.You can download IAPR TC-12 dataset from here. Text-To-SpeechAll three datasets only contains images and the corresponding texts. In order to process cross-modal retrieval across images and audio, I need to turn texts into audio. I use Balabolka for this process. Balabolka is a free TTS program that supports batch processing, which is useful to process huge datasets. Data Pre-processingYou can download the Python program for pre-processing from here Wikipedia Dataset I extract the first sentence of every article and save it in TXT file with the same name as the name of the corresponding image. PASCAL sentences DatasetTexts in PASCAL sentences dataset does not need to be preprocessed since they are already in .txt files. Use Balabolka turn them into audio. IAPR TC-12 DatasetI only use texts in English for this project. The English texts are in a file extensin of .ENG. The ENG file type is primarily associated with Dictionary, but this type can be treated as an XML file because an ENG file has tags which is the same as an XML file. I use Python 3 to read the ENG file and process them as processing XML files and save every description of the corresponding image in a TXT file with the same name as the name of the corresponding ENG file. Dataset after pre-processing and TTSThe following datasets contains audio, texts and images. You can download them from Google Drive. Wikipedia DatastText(XML) location: /wikipedia_dataset/textsText(TXT) location: /wikipedia_datast/audio_textAudio location: /wikipedia_datast/audioImage location: /wikipedia_datast/images PASCAL sentences DatasetText location: /PascalSentenceDataset/sentence/(each category)Audio location: /PascalSentenceDataset/sentence/(each category)/(each directory)Image location: /PascalSentenceDataset/dataset IAPR TC-12 DatasetText location: /iaprtc12/textAudio location: /iaprtc12/audioImage location: /iaprtc12/images References:[1] J. Jeon, V. Lavrenko, and R. Manmatha, “Automatic image annotationand retrieval using cross-media relevance models,” in InternationalACM SIGIR Conference on Research and Development in InformationRetrieval (SIGIR), 2003, pp. 119–126.[2] Cyrus Rashtchian, Peter Young, Micah Hodosh, and Julia Hockenmaier. Collecting Image Annotations Using Amazon’s Mechanical Turk. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk.[3] The IAPR Benchmark: A New Evaluation Resource for Visual Information Systems, Grubinger, Michael, Clough Paul D., Müller Henning, and Deselaers Thomas , International Conference on Language Resources and Evaluation, 24/05/2006, Genoa, Italy, (2006)","link":"/2020/06/28/Cross-modal-retrieval-across-audio-and-images/"},{"title":"Writing using Air Gestures","text":"Githubhttps://github.com/infinitusposs/Writing-using-Air-Gestures IntroductionThis project is a combination of object detection and image classification based on the IOS edge device. Through the device’s camera, detecting the user’s fingertip and tracking the movement of the fingertip with a black line. And then using image classification to recognize the digits that users have written. Instructions: one finger for drawing, two fingers for pausing drawing, three fingers for clearing the screen. Video demoDemo ReportThe report contains all the details about the project. Colab NotebookGoogle Colab ReferencesCPPN: http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/Google edge TF Lite IOS tutorial: https://cloud.google.com/vision/automl/object-detection/docs/tflite-ios-tutorialKaggle dataset “Fingers”: https://www.kaggle.com/koryakinp/fingers (Unused for the final version)","link":"/2020/03/19/Writing-using-Air-Gestures/"},{"title":"Market Forecasting Using Deep Learning Model","text":"GithubVisit https://github.com/infinitusposs/CMPT419-Project-by-Triple-A Poster IntroductionIn recent years, deep learning has developed rapidly. More and more researchershave applied deep learning to different fields, like data analysis, predictions. Interms of predictions, many neural networks, which are an important part of deeplearning, have been used in predicting stock price. In this project, we will focuson predicting the revenue of companies. We test and compare the performancesof Recurrent Neural Network (RNN) and Multilayer Perceptron (MLP) and try tofigure out a better neural network for predicting the revenue of companies. Theresult indicates that MLP is a better neural network for making predictions on therevenue of companies in the next quarter. Multi-layer Perceptron Recurrent Neural Network DatasetApple Financial Report.csv ResultMLP RNN ConclusionRNN performs better on stock market prediction because the price highly depends on the previous days. However, regarding the revenue of companies, the revenue highly depends on the decision they make in the quarter. This is also because we changed the dataset so that whether new products come out has been directly connected to the revenue of the corresponding quarter.In conclusion, Multilayer Perceptron neural network is a better choice for forecasting companies’ profits. Future workSo far, many neural networks have been used in stock price prediction, such as Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). And for predicting stock prices, CNN is the best choice and both LSTM and RNN have better performances than MLP since stock prices heavily depend on the price of the previous days.For the future work, we are going to test the performances of more neural networks like LSTM. Since LSTM is a special type RNN, we expect that LSTM will have a similar performance as RNN. Also, CNN is another choice for this project. We assume CNN will have the best performance on market profit forecasting since it did well in stock forecasting and it does not depend on the previous data. References[1] Najafabadi, M. M., Villanustre, F., Khoshgoftaar, T. M., Seliya, N., Wald, R., &amp; Muharemagic, E. (2015). Deep learning applications and challenges in big data analytics. Journal of Big Data, 2(1), 1.[2] Vaisla, K. S., &amp; Bhatt, A. K. (2010). An analysis of the performance of artificial neural network technique for stock market forecasting. International Journal on Computer Science and Engineering, 2(6), 2104-2109.[3] Hiransha, M., Gopalakrishnan, E. A., Menon, V. K., &amp; Soman, K. P. (2018). NSE stock market prediction using deep-learning models. Procedia computer science, 132, 1351-1362.","link":"/2020/06/28/Market-Forecasting-Using-Deep-Learning-Model/"}],"tags":[{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"},{"name":"Cross-modal retrieval","slug":"Cross-modal-retrieval","link":"/tags/Cross-modal-retrieval/"},{"name":"Wikipedia dataset","slug":"Wikipedia-dataset","link":"/tags/Wikipedia-dataset/"},{"name":"Python 3","slug":"Python-3","link":"/tags/Python-3/"},{"name":"Deep learning","slug":"Deep-learning","link":"/tags/Deep-learning/"},{"name":"Swift","slug":"Swift","link":"/tags/Swift/"},{"name":"Object detection","slug":"Object-detection","link":"/tags/Object-detection/"},{"name":"Image classification","slug":"Image-classification","link":"/tags/Image-classification/"},{"name":"iOS","slug":"iOS","link":"/tags/iOS/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"MLP","slug":"MLP","link":"/tags/MLP/"},{"name":"Market Forecasting","slug":"Market-Forecasting","link":"/tags/Market-Forecasting/"}],"categories":[{"name":"Personal Project","slug":"Personal-Project","link":"/categories/Personal-Project/"},{"name":"Group Project","slug":"Group-Project","link":"/categories/Group-Project/"}]}