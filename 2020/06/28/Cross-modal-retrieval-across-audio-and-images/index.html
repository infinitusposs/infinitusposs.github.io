<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Cross-modal retrieval across audio and images - Infinitusposs - Always trust yourself</title><meta description="This project aims to retrieve the pertinent sample across images and audio. DatasetWikipedia Dataset [1]The collected documents are selected sections from the Wikipedia’s featured articles collection."><meta property="og:type" content="blog"><meta property="og:title" content="Cross-modal retrieval across audio and images"><meta property="og:url" content="http://yoursite.com/2020/06/28/Cross-modal-retrieval-across-audio-and-images/"><meta property="og:site_name" content="Infinitusposs - Always trust yourself"><meta property="og:description" content="This project aims to retrieve the pertinent sample across images and audio. DatasetWikipedia Dataset [1]The collected documents are selected sections from the Wikipedia’s featured articles collection."><meta property="og:locale" content="en_US"><meta property="og:image" content="http://yoursite.com/img/og_image.png"><meta property="article:published_time" content="2020-06-28T07:20:32.000Z"><meta property="article:modified_time" content="2020-06-28T11:01:37.786Z"><meta property="article:author" content="Yufei Wang"><meta property="article:tag" content="Cross-modal"><meta property="article:tag" content="Wikipedia dataset"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2020/06/28/Cross-modal-retrieval-across-audio-and-images/"},"headline":"Infinitusposs - Always trust yourself","image":["http://yoursite.com/img/og_image.png"],"datePublished":"2020-06-28T07:20:32.000Z","dateModified":"2020-06-28T11:01:37.786Z","author":{"@type":"Person","name":"Yufei Wang"},"description":"This project aims to retrieve the pertinent sample across images and audio. DatasetWikipedia Dataset [1]The collected documents are selected sections from the Wikipedia’s featured articles collection."}</script><link rel="canonical" href="http://yoursite.com/2020/06/28/Cross-modal-retrieval-across-audio-and-images/"><link rel="icon" href="/img/f_logo.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/blog_logo.png" alt="Infinitusposs - Always trust yourself" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-06-28T07:20:32.000Z" title="2020-06-28T07:20:32.000Z">2020-06-28</time><span class="level-item"><a class="link-muted" href="/categories/Personal-Project/">Personal Project</a></span><span class="level-item">6 minutes read (About 836 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Cross-modal retrieval across audio and images</h1><div class="content"><p>This project aims to retrieve the pertinent sample across images and audio.</p>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p><strong>Wikipedia Dataset</strong> <sup>[1]</sup><br>The collected documents are selected sections from the Wikipedia’s featured articles collection. This is a continuously growing dataset, that at the time of collection (October 2009) had 2,669 articles spread over 29 categories. Some of the categories are very scarce, therefore we considered only the 10 most populated ones. The articles generally have multiple sections and pictures. We have split them into sections based on section headings, and assign each image to the section in which it was placed by the author(s). Then this dataset was prunned to keep only sections that contained a single image and at least 70 words.<br>The final corpus contains 2,866 multimedia documents. The median text length is 200 words.<br>You can download Wikipedia Dataset from <a href="http://www.svcl.ucsd.edu/projects/crossmodal" title="Download Wikipedia dataset"><ins><strong>here</strong></ins></a>.</p>
<p><strong>PASCAL sentences Dataset</strong> <sup>[2]</sup><br>This dataset contains 1,000 images from 20 categories, and each image has 5 corresponding sentences as exact descriptions.<br>The original dataset is posted on this <a href="https://vision.cs.uiuc.edu/pascal-sentences/" title="PASCAL sentences dataset"><ins><strong>website</strong></ins></a>.<br>You can download this dataset through <a href="https://github.com/rupy/PascalSentenceDataset" title="Download PASCAL dataset using Python 2"><ins><strong>rupy’s python program</strong></ins></a>.<br>However, rupy’s python program is based on Python 2. The <a href="https://github.com/infinitusposs/PascalSentencePython3" title="Download PASCAL dataset using Python 3"><ins><strong>modified program</strong></ins></a>is based on Python 3, and you can use the program as described in rupy’s program.</p>
<p><strong>IAPR TC-12 Dataset</strong><br>The image collection of the IAPR TC-12 Benchmark consists of 20,000 still natural images taken from locations around the world and comprising an assorted cross-section of still natural images. This includes pictures of different sports and actions, photographs of people, animals, cities, landscapes and many other aspects of contemporary life.<br>Each image is associated with a text caption in up to three different languages (English, German and Spanish) . These annotations are stored in a database which is managed by a benchmark administration system that allows the specification of parameters according to which different subsets of the image collection can be generated.<br>You can download IAPR TC-12 dataset from <a href="https://www.imageclef.org/photodata" title="Download IAPR TC-12 dataset"><ins><strong>here</strong></ins></a>.</p>
<h2 id="Text-To-Speech"><a href="#Text-To-Speech" class="headerlink" title="Text-To-Speech"></a>Text-To-Speech</h2><p>All three datasets only contains images and the corresponding texts. In order to process cross-modal retrieval across images and audio, I need to turn texts into audio. I use <a href="http://www.cross-plus-a.com/balabolka.htm" title="Download Balabolka"><ins><strong>Balabolka</strong></ins></a> for this process. Balabolka is a free TTS program that supports batch processing, which is useful to process huge datasets.</p>
<h2 id="Data-Pre-processing"><a href="#Data-Pre-processing" class="headerlink" title="Data Pre-processing"></a>Data Pre-processing</h2><p>You can download the Python program for pre-processing from <a href="https://github.com/infinitusposs/preprocessing-datasets" title="Download program for preprocessing"><ins><strong>here</strong></ins></a></p>
<p><strong>Wikipedia Dataset</strong><br> I extract the first sentence of every article and save it in TXT file with the same name as the name of the corresponding image.</p>
<p><strong>PASCAL sentences Dataset</strong><br>Texts in PASCAL sentences dataset does not need to be preprocessed since they are already in .txt files. Use Balabolka turn them into audio. </p>
<p><strong>IAPR TC-12 Dataset</strong><br>I only use texts in English for this project. The English texts are in a file extensin of .ENG. The ENG file type is primarily associated with Dictionary, but this type can be treated as an XML file because an ENG file has tags which is the same as an XML file. I use Python 3 to read the ENG file and process them as processing XML files and save every description of the corresponding image in a TXT file with the same name as the name of the corresponding ENG file.</p>
<h2 id="Dataset-after-pre-processing-and-TTS"><a href="#Dataset-after-pre-processing-and-TTS" class="headerlink" title="Dataset after pre-processing and TTS"></a>Dataset after pre-processing and TTS</h2><p>The following datasets contains audio, texts and images. You can download them from Google Drive. </p>
<p><a href="https://drive.google.com/uc?export=download&id=1IqZ0PLMq_pDF31JniwQx5oRdY4gX_Rqw" title="Wikipedia dataset with audio"><ins><strong>Wikipedia Datast</strong></ins></a><br>Text(XML) location: /wikipedia_dataset/texts<br>Text(TXT) location: /wikipedia_datast/audio_text<br>Audio location: /wikipedia_datast/audio<br>Image location: /wikipedia_datast/images</p>
<p><a href="https://drive.google.com/uc?export=download&id=1Z7oL-EFMFS8bRDa0tCANho8GJ2zj1dHV" title="PASCAL sentences dataset with audio"><ins><strong>PASCAL sentences Dataset</strong></ins></a><br>Text location: /PascalSentenceDataset/sentence/(each category)<br>Audio location: /PascalSentenceDataset/sentence/(each category)/(each directory)<br>Image location: /PascalSentenceDataset/dataset</p>
<p><a href="https://drive.google.com/uc?export=download&id=1NA4DQwMMJO4qnA-_Z50XzmW4Lx5YTLx9" title="IAPR TC-12 dataset with audio"><ins><strong>IAPR TC-12 Dataset</strong></ins></a><br>Text location: /iaprtc12/text<br>Audio location: /iaprtc12/audio<br>Image location: /iaprtc12/images</p>
<h2 id="References"><a href="#References" class="headerlink" title="References:"></a>References:</h2><p>[1] J. Jeon, V. Lavrenko, and R. Manmatha, “Automatic image annotation<br>and retrieval using cross-media relevance models,” in International<br>ACM SIGIR Conference on Research and Development in Information<br>Retrieval (SIGIR), 2003, pp. 119–126.<br>[2] Cyrus Rashtchian, Peter Young, Micah Hodosh, and Julia Hockenmaier. Collecting Image Annotations Using Amazon’s Mechanical Turk. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk.<br>[3] The IAPR Benchmark: A New Evaluation Resource for Visual Information Systems, Grubinger, Michael, Clough Paul D., Müller Henning, and Deselaers Thomas , International Conference on Language Resources and Evaluation, 24/05/2006, Genoa, Italy, (2006)</p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Cross-modal/">Cross-modal</a><a class="link-muted mr-2" rel="tag" href="/tags/Wikipedia-dataset/">Wikipedia dataset</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button is-danger donate" href="/" target="_blank" rel="noopener"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/03/19/Writing-using-Air-Gestures/"><span class="level-item">Writing using Air Gestures</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/hayate.jpeg" alt="Infinitusposs"></figure><p class="title is-size-4 is-block line-height-inherit">Infinitusposs</p><p class="is-size-6 is-block">SFU Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Canada</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Category</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">7</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/infinitusposs" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/infinitusposs/"><i class="fab fa-github"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://fantasyonly.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Brother Nie</span></span><span class="level-right"><span class="level-item tag">fantasyonly.github.io</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Personal-Project/"><span class="level-start"><span class="level-item">Personal Project</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/03/"><span class="level-start"><span class="level-item">March 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Computer-vision/"><span class="tag">Computer vision</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-modal/"><span class="tag">Cross-modal</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-detection/"><span class="tag">Object detection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Swift/"><span class="tag">Swift</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wikipedia-dataset/"><span class="tag">Wikipedia dataset</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/iOS/"><span class="tag">iOS</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/image-classification/"><span class="tag">image classification</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-28T07:20:32.000Z">2020-06-28</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/28/Cross-modal-retrieval-across-audio-and-images/">Cross-modal retrieval across audio and images</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Personal-Project/">Personal Project</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-19T10:10:00.000Z">2020-03-19</time></p><p class="title is-6"><a class="link-muted" href="/2020/03/19/Writing-using-Air-Gestures/">Writing using Air Gestures</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Personal-Project/">Personal Project</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-03-19T08:10:24.922Z">2020-03-19</time></p><p class="title is-6"><a class="link-muted" href="/2020/03/19/hello-world/">Hello World</a></p><p class="is-uppercase"></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/blog_logo.png" alt="Infinitusposs - Always trust yourself" height="28"></a><p class="size-small"><span>&copy; 2020 Yufei Wang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>